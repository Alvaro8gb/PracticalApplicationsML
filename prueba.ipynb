{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:47:36.869211157Z",
     "start_time": "2023-11-18T19:47:36.864388532Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./my-staff\")\n",
    "from database import load_ds\n",
    "from globals import TEST_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:47:38.131200068Z",
     "start_time": "2023-11-18T19:47:38.128515848Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(293, 25)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, features_names, class_names = load_ds(\"all\")\n",
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:47:38.433311445Z",
     "start_time": "2023-11-18T19:47:38.425559098Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def split(X, y, seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                                y,\n",
    "                                                                test_size=TEST_SIZE,\n",
    "                                                                random_state=seed)\n",
    "    return  X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:47:51.082951109Z",
     "start_time": "2023-11-18T19:47:51.030435955Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:46:55.217496320Z",
     "start_time": "2023-11-18T19:46:55.209336870Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "result = []\n",
    "for seed in range(1000):\n",
    "    X_train, X_test, y_train, y_test = split(X,y , seed)\n",
    "    model = GaussianNB()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    score = model.score(X_test, y_test)\n",
    "    result.append([seed, score])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T11:06:01.408421231Z",
     "start_time": "2023-11-10T11:05:59.476750992Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0, 0.8068181818181818],\n [1, 0.7840909090909091],\n [2, 0.7954545454545454],\n [3, 0.7840909090909091],\n [4, 0.8068181818181818],\n [5, 0.8068181818181818],\n [6, 0.7272727272727273],\n [7, 0.7840909090909091],\n [8, 0.8636363636363636],\n [9, 0.7613636363636364],\n [10, 0.7954545454545454],\n [11, 0.8522727272727273],\n [12, 0.7159090909090909],\n [13, 0.7159090909090909],\n [14, 0.7272727272727273],\n [15, 0.7954545454545454],\n [16, 0.75],\n [17, 0.7386363636363636],\n [18, 0.7272727272727273],\n [19, 0.8068181818181818],\n [20, 0.7159090909090909],\n [21, 0.7840909090909091],\n [22, 0.8295454545454546],\n [23, 0.7840909090909091],\n [24, 0.6818181818181818],\n [25, 0.7727272727272727],\n [26, 0.75],\n [27, 0.8068181818181818],\n [28, 0.7840909090909091],\n [29, 0.8181818181818182],\n [30, 0.75],\n [31, 0.7840909090909091],\n [32, 0.7386363636363636],\n [33, 0.7840909090909091],\n [34, 0.7840909090909091],\n [35, 0.8181818181818182],\n [36, 0.7613636363636364],\n [37, 0.7840909090909091],\n [38, 0.8295454545454546],\n [39, 0.7840909090909091],\n [40, 0.7386363636363636],\n [41, 0.7727272727272727],\n [42, 0.75],\n [43, 0.7386363636363636],\n [44, 0.7272727272727273],\n [45, 0.7840909090909091],\n [46, 0.7727272727272727],\n [47, 0.8409090909090909],\n [48, 0.7954545454545454],\n [49, 0.8295454545454546],\n [50, 0.7045454545454546],\n [51, 0.7613636363636364],\n [52, 0.7727272727272727],\n [53, 0.7613636363636364],\n [54, 0.8181818181818182],\n [55, 0.7840909090909091],\n [56, 0.7613636363636364],\n [57, 0.7386363636363636],\n [58, 0.8181818181818182],\n [59, 0.7727272727272727],\n [60, 0.7159090909090909],\n [61, 0.8181818181818182],\n [62, 0.75],\n [63, 0.7954545454545454],\n [64, 0.75],\n [65, 0.75],\n [66, 0.75],\n [67, 0.7954545454545454],\n [68, 0.7272727272727273],\n [69, 0.7727272727272727],\n [70, 0.8181818181818182],\n [71, 0.7840909090909091],\n [72, 0.8181818181818182],\n [73, 0.6931818181818182],\n [74, 0.7727272727272727],\n [75, 0.8181818181818182],\n [76, 0.7272727272727273],\n [77, 0.7386363636363636],\n [78, 0.8068181818181818],\n [79, 0.7840909090909091],\n [80, 0.75],\n [81, 0.8068181818181818],\n [82, 0.8068181818181818],\n [83, 0.7954545454545454],\n [84, 0.7727272727272727],\n [85, 0.7954545454545454],\n [86, 0.7159090909090909],\n [87, 0.8068181818181818],\n [88, 0.7954545454545454],\n [89, 0.7727272727272727],\n [90, 0.7613636363636364],\n [91, 0.7727272727272727],\n [92, 0.8181818181818182],\n [93, 0.8068181818181818],\n [94, 0.7159090909090909],\n [95, 0.7613636363636364],\n [96, 0.7045454545454546],\n [97, 0.8409090909090909],\n [98, 0.7954545454545454],\n [99, 0.7159090909090909],\n [100, 0.7840909090909091],\n [101, 0.6931818181818182],\n [102, 0.7613636363636364],\n [103, 0.7613636363636364],\n [104, 0.7954545454545454],\n [105, 0.7613636363636364],\n [106, 0.7613636363636364],\n [107, 0.8181818181818182],\n [108, 0.8068181818181818],\n [109, 0.8181818181818182],\n [110, 0.7727272727272727],\n [111, 0.75],\n [112, 0.7954545454545454],\n [113, 0.7613636363636364],\n [114, 0.7272727272727273],\n [115, 0.7840909090909091],\n [116, 0.6931818181818182],\n [117, 0.8181818181818182],\n [118, 0.7159090909090909],\n [119, 0.7727272727272727],\n [120, 0.7613636363636364],\n [121, 0.8068181818181818],\n [122, 0.75],\n [123, 0.7840909090909091],\n [124, 0.7727272727272727],\n [125, 0.7954545454545454],\n [126, 0.7045454545454546],\n [127, 0.8068181818181818],\n [128, 0.7954545454545454],\n [129, 0.7840909090909091],\n [130, 0.7386363636363636],\n [131, 0.7954545454545454],\n [132, 0.7727272727272727],\n [133, 0.7840909090909091],\n [134, 0.7954545454545454],\n [135, 0.7840909090909091],\n [136, 0.7159090909090909],\n [137, 0.7840909090909091],\n [138, 0.7386363636363636],\n [139, 0.75],\n [140, 0.7727272727272727],\n [141, 0.7386363636363636],\n [142, 0.7840909090909091],\n [143, 0.7613636363636364],\n [144, 0.7840909090909091],\n [145, 0.7159090909090909],\n [146, 0.75],\n [147, 0.8068181818181818],\n [148, 0.8295454545454546],\n [149, 0.8181818181818182],\n [150, 0.7840909090909091],\n [151, 0.8181818181818182],\n [152, 0.7954545454545454],\n [153, 0.8295454545454546],\n [154, 0.7727272727272727],\n [155, 0.8181818181818182],\n [156, 0.7613636363636364],\n [157, 0.7727272727272727],\n [158, 0.7954545454545454],\n [159, 0.8068181818181818],\n [160, 0.7159090909090909],\n [161, 0.6931818181818182],\n [162, 0.7840909090909091],\n [163, 0.8068181818181818],\n [164, 0.75],\n [165, 0.7840909090909091],\n [166, 0.8068181818181818],\n [167, 0.75],\n [168, 0.75],\n [169, 0.7386363636363636],\n [170, 0.7386363636363636],\n [171, 0.7386363636363636],\n [172, 0.75],\n [173, 0.8068181818181818],\n [174, 0.75],\n [175, 0.7613636363636364],\n [176, 0.6931818181818182],\n [177, 0.7613636363636364],\n [178, 0.8068181818181818],\n [179, 0.7840909090909091],\n [180, 0.7045454545454546],\n [181, 0.8522727272727273],\n [182, 0.6818181818181818],\n [183, 0.8068181818181818],\n [184, 0.7613636363636364],\n [185, 0.7159090909090909],\n [186, 0.7613636363636364],\n [187, 0.7386363636363636],\n [188, 0.75],\n [189, 0.7386363636363636],\n [190, 0.6363636363636364],\n [191, 0.7272727272727273],\n [192, 0.8068181818181818],\n [193, 0.75],\n [194, 0.8181818181818182],\n [195, 0.75],\n [196, 0.8181818181818182],\n [197, 0.7727272727272727],\n [198, 0.7272727272727273],\n [199, 0.8295454545454546],\n [200, 0.8068181818181818],\n [201, 0.7954545454545454],\n [202, 0.7159090909090909],\n [203, 0.8068181818181818],\n [204, 0.75],\n [205, 0.75],\n [206, 0.7840909090909091],\n [207, 0.8068181818181818],\n [208, 0.7954545454545454],\n [209, 0.7386363636363636],\n [210, 0.75],\n [211, 0.7045454545454546],\n [212, 0.6590909090909091],\n [213, 0.8068181818181818],\n [214, 0.7045454545454546],\n [215, 0.7272727272727273],\n [216, 0.7386363636363636],\n [217, 0.8181818181818182],\n [218, 0.8522727272727273],\n [219, 0.75],\n [220, 0.8295454545454546],\n [221, 0.75],\n [222, 0.7840909090909091],\n [223, 0.7727272727272727],\n [224, 0.7840909090909091],\n [225, 0.7840909090909091],\n [226, 0.7613636363636364],\n [227, 0.7727272727272727],\n [228, 0.7159090909090909],\n [229, 0.8295454545454546],\n [230, 0.7727272727272727],\n [231, 0.7045454545454546],\n [232, 0.8068181818181818],\n [233, 0.75],\n [234, 0.75],\n [235, 0.7954545454545454],\n [236, 0.7613636363636364],\n [237, 0.7727272727272727],\n [238, 0.8295454545454546],\n [239, 0.75],\n [240, 0.8295454545454546],\n [241, 0.7727272727272727],\n [242, 0.75],\n [243, 0.75],\n [244, 0.7727272727272727],\n [245, 0.7045454545454546],\n [246, 0.7159090909090909],\n [247, 0.6818181818181818],\n [248, 0.8181818181818182],\n [249, 0.75],\n [250, 0.7613636363636364],\n [251, 0.7727272727272727],\n [252, 0.7272727272727273],\n [253, 0.7840909090909091],\n [254, 0.7840909090909091],\n [255, 0.8295454545454546],\n [256, 0.7386363636363636],\n [257, 0.7727272727272727],\n [258, 0.8068181818181818],\n [259, 0.8295454545454546],\n [260, 0.7727272727272727],\n [261, 0.7272727272727273],\n [262, 0.7840909090909091],\n [263, 0.7840909090909091],\n [264, 0.8522727272727273],\n [265, 0.7840909090909091],\n [266, 0.7386363636363636],\n [267, 0.75],\n [268, 0.7613636363636364],\n [269, 0.8068181818181818],\n [270, 0.7727272727272727],\n [271, 0.7045454545454546],\n [272, 0.8295454545454546],\n [273, 0.7840909090909091],\n [274, 0.7613636363636364],\n [275, 0.8181818181818182],\n [276, 0.75],\n [277, 0.6704545454545454],\n [278, 0.7954545454545454],\n [279, 0.8181818181818182],\n [280, 0.8181818181818182],\n [281, 0.7727272727272727],\n [282, 0.7954545454545454],\n [283, 0.7727272727272727],\n [284, 0.7272727272727273],\n [285, 0.7840909090909091],\n [286, 0.8409090909090909],\n [287, 0.7954545454545454],\n [288, 0.7727272727272727],\n [289, 0.75],\n [290, 0.7045454545454546],\n [291, 0.7386363636363636],\n [292, 0.8181818181818182],\n [293, 0.7272727272727273],\n [294, 0.7727272727272727],\n [295, 0.6818181818181818],\n [296, 0.7159090909090909],\n [297, 0.7727272727272727],\n [298, 0.7613636363636364],\n [299, 0.7045454545454546],\n [300, 0.8068181818181818],\n [301, 0.75],\n [302, 0.8295454545454546],\n [303, 0.75],\n [304, 0.7613636363636364],\n [305, 0.7386363636363636],\n [306, 0.7727272727272727],\n [307, 0.7613636363636364],\n [308, 0.7159090909090909],\n [309, 0.8068181818181818],\n [310, 0.7727272727272727],\n [311, 0.75],\n [312, 0.7386363636363636],\n [313, 0.7954545454545454],\n [314, 0.7613636363636364],\n [315, 0.7045454545454546],\n [316, 0.7386363636363636],\n [317, 0.6590909090909091],\n [318, 0.8068181818181818],\n [319, 0.7613636363636364],\n [320, 0.7272727272727273],\n [321, 0.7045454545454546],\n [322, 0.7159090909090909],\n [323, 0.7159090909090909],\n [324, 0.7840909090909091],\n [325, 0.7045454545454546],\n [326, 0.7840909090909091],\n [327, 0.8068181818181818],\n [328, 0.7272727272727273],\n [329, 0.7613636363636364],\n [330, 0.8068181818181818],\n [331, 0.8409090909090909],\n [332, 0.7954545454545454],\n [333, 0.7613636363636364],\n [334, 0.7386363636363636],\n [335, 0.7954545454545454],\n [336, 0.8068181818181818],\n [337, 0.8181818181818182],\n [338, 0.8068181818181818],\n [339, 0.7613636363636364],\n [340, 0.8181818181818182],\n [341, 0.8295454545454546],\n [342, 0.8068181818181818],\n [343, 0.7613636363636364],\n [344, 0.7045454545454546],\n [345, 0.7954545454545454],\n [346, 0.7727272727272727],\n [347, 0.7954545454545454],\n [348, 0.7727272727272727],\n [349, 0.8068181818181818],\n [350, 0.75],\n [351, 0.7727272727272727],\n [352, 0.8522727272727273],\n [353, 0.8295454545454546],\n [354, 0.7727272727272727],\n [355, 0.7272727272727273],\n [356, 0.8181818181818182],\n [357, 0.7272727272727273],\n [358, 0.7727272727272727],\n [359, 0.75],\n [360, 0.7386363636363636],\n [361, 0.6363636363636364],\n [362, 0.7272727272727273],\n [363, 0.8068181818181818],\n [364, 0.7727272727272727],\n [365, 0.7159090909090909],\n [366, 0.7727272727272727],\n [367, 0.7727272727272727],\n [368, 0.7954545454545454],\n [369, 0.7045454545454546],\n [370, 0.7613636363636364],\n [371, 0.7272727272727273],\n [372, 0.8295454545454546],\n [373, 0.7727272727272727],\n [374, 0.7727272727272727],\n [375, 0.7613636363636364],\n [376, 0.7840909090909091],\n [377, 0.7727272727272727],\n [378, 0.8181818181818182],\n [379, 0.7840909090909091],\n [380, 0.7954545454545454],\n [381, 0.8181818181818182],\n [382, 0.7613636363636364],\n [383, 0.7386363636363636],\n [384, 0.7613636363636364],\n [385, 0.75],\n [386, 0.7727272727272727],\n [387, 0.7613636363636364],\n [388, 0.7386363636363636],\n [389, 0.7954545454545454],\n [390, 0.7386363636363636],\n [391, 0.7727272727272727],\n [392, 0.7840909090909091],\n [393, 0.7386363636363636],\n [394, 0.75],\n [395, 0.7727272727272727],\n [396, 0.8068181818181818],\n [397, 0.7840909090909091],\n [398, 0.7954545454545454],\n [399, 0.7727272727272727],\n [400, 0.7840909090909091],\n [401, 0.6590909090909091],\n [402, 0.8068181818181818],\n [403, 0.7727272727272727],\n [404, 0.6818181818181818],\n [405, 0.7840909090909091],\n [406, 0.7954545454545454],\n [407, 0.8068181818181818],\n [408, 0.7613636363636364],\n [409, 0.7727272727272727],\n [410, 0.6931818181818182],\n [411, 0.7386363636363636],\n [412, 0.75],\n [413, 0.8522727272727273],\n [414, 0.7727272727272727],\n [415, 0.7272727272727273],\n [416, 0.7954545454545454],\n [417, 0.7954545454545454],\n [418, 0.7272727272727273],\n [419, 0.7272727272727273],\n [420, 0.8181818181818182],\n [421, 0.7613636363636364],\n [422, 0.8068181818181818],\n [423, 0.7159090909090909],\n [424, 0.7613636363636364],\n [425, 0.75],\n [426, 0.8522727272727273],\n [427, 0.6818181818181818],\n [428, 0.7272727272727273],\n [429, 0.8181818181818182],\n [430, 0.7159090909090909],\n [431, 0.8068181818181818],\n [432, 0.6818181818181818],\n [433, 0.7840909090909091],\n [434, 0.8409090909090909],\n [435, 0.7727272727272727],\n [436, 0.7954545454545454],\n [437, 0.8409090909090909],\n [438, 0.75],\n [439, 0.7954545454545454],\n [440, 0.6931818181818182],\n [441, 0.8068181818181818],\n [442, 0.8295454545454546],\n [443, 0.8181818181818182],\n [444, 0.75],\n [445, 0.7613636363636364],\n [446, 0.75],\n [447, 0.8068181818181818],\n [448, 0.7840909090909091],\n [449, 0.7840909090909091],\n [450, 0.75],\n [451, 0.7613636363636364],\n [452, 0.7954545454545454],\n [453, 0.7386363636363636],\n [454, 0.7613636363636364],\n [455, 0.7386363636363636],\n [456, 0.75],\n [457, 0.7613636363636364],\n [458, 0.7954545454545454],\n [459, 0.7386363636363636],\n [460, 0.7954545454545454],\n [461, 0.7840909090909091],\n [462, 0.7613636363636364],\n [463, 0.7840909090909091],\n [464, 0.6931818181818182],\n [465, 0.8068181818181818],\n [466, 0.8181818181818182],\n [467, 0.7613636363636364],\n [468, 0.7840909090909091],\n [469, 0.7386363636363636],\n [470, 0.75],\n [471, 0.7386363636363636],\n [472, 0.7840909090909091],\n [473, 0.75],\n [474, 0.7159090909090909],\n [475, 0.75],\n [476, 0.6931818181818182],\n [477, 0.7727272727272727],\n [478, 0.75],\n [479, 0.8068181818181818],\n [480, 0.7386363636363636],\n [481, 0.7840909090909091],\n [482, 0.75],\n [483, 0.7840909090909091],\n [484, 0.7954545454545454],\n [485, 0.7840909090909091],\n [486, 0.8409090909090909],\n [487, 0.7272727272727273],\n [488, 0.7954545454545454],\n [489, 0.8295454545454546],\n [490, 0.7272727272727273],\n [491, 0.7045454545454546],\n [492, 0.7386363636363636],\n [493, 0.7727272727272727],\n [494, 0.7840909090909091],\n [495, 0.8068181818181818],\n [496, 0.7727272727272727],\n [497, 0.7613636363636364],\n [498, 0.7840909090909091],\n [499, 0.7727272727272727],\n [500, 0.7954545454545454],\n [501, 0.7840909090909091],\n [502, 0.8068181818181818],\n [503, 0.75],\n [504, 0.7954545454545454],\n [505, 0.7727272727272727],\n [506, 0.7272727272727273],\n [507, 0.8295454545454546],\n [508, 0.7613636363636364],\n [509, 0.7840909090909091],\n [510, 0.8409090909090909],\n [511, 0.7272727272727273],\n [512, 0.6818181818181818],\n [513, 0.7840909090909091],\n [514, 0.8409090909090909],\n [515, 0.7613636363636364],\n [516, 0.7727272727272727],\n [517, 0.7386363636363636],\n [518, 0.7727272727272727],\n [519, 0.7727272727272727],\n [520, 0.8068181818181818],\n [521, 0.7272727272727273],\n [522, 0.7727272727272727],\n [523, 0.7045454545454546],\n [524, 0.7613636363636364],\n [525, 0.8068181818181818],\n [526, 0.8295454545454546],\n [527, 0.8409090909090909],\n [528, 0.7727272727272727],\n [529, 0.7727272727272727],\n [530, 0.8409090909090909],\n [531, 0.75],\n [532, 0.7159090909090909],\n [533, 0.7840909090909091],\n [534, 0.7613636363636364],\n [535, 0.75],\n [536, 0.8068181818181818],\n [537, 0.7727272727272727],\n [538, 0.8181818181818182],\n [539, 0.7613636363636364],\n [540, 0.7613636363636364],\n [541, 0.7045454545454546],\n [542, 0.7613636363636364],\n [543, 0.7613636363636364],\n [544, 0.8068181818181818],\n [545, 0.8181818181818182],\n [546, 0.7954545454545454],\n [547, 0.7386363636363636],\n [548, 0.6931818181818182],\n [549, 0.7272727272727273],\n [550, 0.7954545454545454],\n [551, 0.8068181818181818],\n [552, 0.7954545454545454],\n [553, 0.7613636363636364],\n [554, 0.7386363636363636],\n [555, 0.8181818181818182],\n [556, 0.7386363636363636],\n [557, 0.8068181818181818],\n [558, 0.8068181818181818],\n [559, 0.7840909090909091],\n [560, 0.7727272727272727],\n [561, 0.7840909090909091],\n [562, 0.8181818181818182],\n [563, 0.75],\n [564, 0.8295454545454546],\n [565, 0.8181818181818182],\n [566, 0.7613636363636364],\n [567, 0.7386363636363636],\n [568, 0.7613636363636364],\n [569, 0.75],\n [570, 0.8295454545454546],\n [571, 0.7386363636363636],\n [572, 0.8068181818181818],\n [573, 0.7840909090909091],\n [574, 0.7386363636363636],\n [575, 0.8181818181818182],\n [576, 0.7954545454545454],\n [577, 0.7954545454545454],\n [578, 0.7840909090909091],\n [579, 0.7954545454545454],\n [580, 0.7272727272727273],\n [581, 0.7727272727272727],\n [582, 0.7613636363636364],\n [583, 0.7613636363636364],\n [584, 0.7840909090909091],\n [585, 0.7727272727272727],\n [586, 0.75],\n [587, 0.7954545454545454],\n [588, 0.7272727272727273],\n [589, 0.7386363636363636],\n [590, 0.8068181818181818],\n [591, 0.8863636363636364],\n [592, 0.7840909090909091],\n [593, 0.7954545454545454],\n [594, 0.7272727272727273],\n [595, 0.7045454545454546],\n [596, 0.7386363636363636],\n [597, 0.7613636363636364],\n [598, 0.7613636363636364],\n [599, 0.7386363636363636],\n [600, 0.7954545454545454],\n [601, 0.7386363636363636],\n [602, 0.7272727272727273],\n [603, 0.8409090909090909],\n [604, 0.7613636363636364],\n [605, 0.8068181818181818],\n [606, 0.7727272727272727],\n [607, 0.6590909090909091],\n [608, 0.7727272727272727],\n [609, 0.7840909090909091],\n [610, 0.7159090909090909],\n [611, 0.7613636363636364],\n [612, 0.8295454545454546],\n [613, 0.75],\n [614, 0.7613636363636364],\n [615, 0.6931818181818182],\n [616, 0.7727272727272727],\n [617, 0.7045454545454546],\n [618, 0.8181818181818182],\n [619, 0.7045454545454546],\n [620, 0.7613636363636364],\n [621, 0.7613636363636364],\n [622, 0.8295454545454546],\n [623, 0.7840909090909091],\n [624, 0.7045454545454546],\n [625, 0.8295454545454546],\n [626, 0.8409090909090909],\n [627, 0.7727272727272727],\n [628, 0.8068181818181818],\n [629, 0.7954545454545454],\n [630, 0.7954545454545454],\n [631, 0.7272727272727273],\n [632, 0.7727272727272727],\n [633, 0.7613636363636364],\n [634, 0.7159090909090909],\n [635, 0.7840909090909091],\n [636, 0.7840909090909091],\n [637, 0.75],\n [638, 0.75],\n [639, 0.6931818181818182],\n [640, 0.7840909090909091],\n [641, 0.8181818181818182],\n [642, 0.7840909090909091],\n [643, 0.7840909090909091],\n [644, 0.7727272727272727],\n [645, 0.7386363636363636],\n [646, 0.7727272727272727],\n [647, 0.7386363636363636],\n [648, 0.8068181818181818],\n [649, 0.7954545454545454],\n [650, 0.75],\n [651, 0.7045454545454546],\n [652, 0.7840909090909091],\n [653, 0.7386363636363636],\n [654, 0.7840909090909091],\n [655, 0.7613636363636364],\n [656, 0.7386363636363636],\n [657, 0.8522727272727273],\n [658, 0.75],\n [659, 0.6931818181818182],\n [660, 0.7272727272727273],\n [661, 0.7840909090909091],\n [662, 0.7613636363636364],\n [663, 0.7613636363636364],\n [664, 0.8181818181818182],\n [665, 0.7159090909090909],\n [666, 0.7954545454545454],\n [667, 0.7272727272727273],\n [668, 0.7613636363636364],\n [669, 0.7272727272727273],\n [670, 0.7954545454545454],\n [671, 0.7159090909090909],\n [672, 0.7840909090909091],\n [673, 0.7840909090909091],\n [674, 0.8068181818181818],\n [675, 0.7613636363636364],\n [676, 0.8068181818181818],\n [677, 0.75],\n [678, 0.7613636363636364],\n [679, 0.7613636363636364],\n [680, 0.8181818181818182],\n [681, 0.6477272727272727],\n [682, 0.7840909090909091],\n [683, 0.75],\n [684, 0.75],\n [685, 0.7954545454545454],\n [686, 0.6477272727272727],\n [687, 0.7954545454545454],\n [688, 0.7613636363636364],\n [689, 0.8068181818181818],\n [690, 0.7159090909090909],\n [691, 0.7272727272727273],\n [692, 0.7272727272727273],\n [693, 0.7727272727272727],\n [694, 0.8068181818181818],\n [695, 0.7954545454545454],\n [696, 0.7727272727272727],\n [697, 0.8295454545454546],\n [698, 0.7727272727272727],\n [699, 0.7840909090909091],\n [700, 0.7613636363636364],\n [701, 0.7159090909090909],\n [702, 0.7613636363636364],\n [703, 0.7386363636363636],\n [704, 0.7727272727272727],\n [705, 0.7727272727272727],\n [706, 0.8295454545454546],\n [707, 0.7159090909090909],\n [708, 0.8295454545454546],\n [709, 0.8295454545454546],\n [710, 0.7840909090909091],\n [711, 0.8068181818181818],\n [712, 0.8409090909090909],\n [713, 0.7386363636363636],\n [714, 0.7840909090909091],\n [715, 0.7159090909090909],\n [716, 0.7954545454545454],\n [717, 0.75],\n [718, 0.75],\n [719, 0.7613636363636364],\n [720, 0.8068181818181818],\n [721, 0.7727272727272727],\n [722, 0.6818181818181818],\n [723, 0.75],\n [724, 0.75],\n [725, 0.7840909090909091],\n [726, 0.7386363636363636],\n [727, 0.7727272727272727],\n [728, 0.7954545454545454],\n [729, 0.7840909090909091],\n [730, 0.75],\n [731, 0.7386363636363636],\n [732, 0.8409090909090909],\n [733, 0.7840909090909091],\n [734, 0.7727272727272727],\n [735, 0.7954545454545454],\n [736, 0.7613636363636364],\n [737, 0.8181818181818182],\n [738, 0.7727272727272727],\n [739, 0.7386363636363636],\n [740, 0.7727272727272727],\n [741, 0.7045454545454546],\n [742, 0.7954545454545454],\n [743, 0.7840909090909091],\n [744, 0.75],\n [745, 0.7613636363636364],\n [746, 0.8181818181818182],\n [747, 0.7613636363636364],\n [748, 0.7272727272727273],\n [749, 0.7386363636363636],\n [750, 0.7727272727272727],\n [751, 0.7159090909090909],\n [752, 0.8295454545454546],\n [753, 0.8068181818181818],\n [754, 0.7386363636363636],\n [755, 0.8068181818181818],\n [756, 0.6818181818181818],\n [757, 0.7159090909090909],\n [758, 0.7613636363636364],\n [759, 0.7727272727272727],\n [760, 0.7159090909090909],\n [761, 0.8522727272727273],\n [762, 0.8068181818181818],\n [763, 0.7613636363636364],\n [764, 0.7613636363636364],\n [765, 0.7159090909090909],\n [766, 0.8295454545454546],\n [767, 0.7727272727272727],\n [768, 0.7954545454545454],\n [769, 0.7272727272727273],\n [770, 0.7613636363636364],\n [771, 0.7386363636363636],\n [772, 0.7613636363636364],\n [773, 0.7613636363636364],\n [774, 0.7045454545454546],\n [775, 0.7954545454545454],\n [776, 0.8181818181818182],\n [777, 0.7272727272727273],\n [778, 0.7386363636363636],\n [779, 0.7727272727272727],\n [780, 0.7272727272727273],\n [781, 0.7613636363636364],\n [782, 0.75],\n [783, 0.7840909090909091],\n [784, 0.7840909090909091],\n [785, 0.7840909090909091],\n [786, 0.7840909090909091],\n [787, 0.8636363636363636],\n [788, 0.6590909090909091],\n [789, 0.8409090909090909],\n [790, 0.7727272727272727],\n [791, 0.75],\n [792, 0.75],\n [793, 0.7613636363636364],\n [794, 0.8295454545454546],\n [795, 0.8068181818181818],\n [796, 0.7159090909090909],\n [797, 0.8181818181818182],\n [798, 0.8295454545454546],\n [799, 0.7840909090909091],\n [800, 0.7386363636363636],\n [801, 0.7840909090909091],\n [802, 0.7386363636363636],\n [803, 0.7272727272727273],\n [804, 0.7727272727272727],\n [805, 0.7727272727272727],\n [806, 0.7386363636363636],\n [807, 0.8181818181818182],\n [808, 0.75],\n [809, 0.7727272727272727],\n [810, 0.8068181818181818],\n [811, 0.7727272727272727],\n [812, 0.7613636363636364],\n [813, 0.8636363636363636],\n [814, 0.75],\n [815, 0.7613636363636364],\n [816, 0.75],\n [817, 0.75],\n [818, 0.7613636363636364],\n [819, 0.75],\n [820, 0.8068181818181818],\n [821, 0.75],\n [822, 0.7159090909090909],\n [823, 0.7613636363636364],\n [824, 0.7386363636363636],\n [825, 0.7840909090909091],\n [826, 0.7386363636363636],\n [827, 0.7386363636363636],\n [828, 0.75],\n [829, 0.7272727272727273],\n [830, 0.75],\n [831, 0.7613636363636364],\n [832, 0.7272727272727273],\n [833, 0.6931818181818182],\n [834, 0.7272727272727273],\n [835, 0.8068181818181818],\n [836, 0.7954545454545454],\n [837, 0.7386363636363636],\n [838, 0.7954545454545454],\n [839, 0.7840909090909091],\n [840, 0.75],\n [841, 0.7840909090909091],\n [842, 0.75],\n [843, 0.7613636363636364],\n [844, 0.8295454545454546],\n [845, 0.7613636363636364],\n [846, 0.7613636363636364],\n [847, 0.6818181818181818],\n [848, 0.7727272727272727],\n [849, 0.7613636363636364],\n [850, 0.7613636363636364],\n [851, 0.7727272727272727],\n [852, 0.7613636363636364],\n [853, 0.6931818181818182],\n [854, 0.7386363636363636],\n [855, 0.7954545454545454],\n [856, 0.8068181818181818],\n [857, 0.7272727272727273],\n [858, 0.7386363636363636],\n [859, 0.7840909090909091],\n [860, 0.7954545454545454],\n [861, 0.7159090909090909],\n [862, 0.7727272727272727],\n [863, 0.7840909090909091],\n [864, 0.7954545454545454],\n [865, 0.7840909090909091],\n [866, 0.8068181818181818],\n [867, 0.6704545454545454],\n [868, 0.8181818181818182],\n [869, 0.75],\n [870, 0.7613636363636364],\n [871, 0.7159090909090909],\n [872, 0.7386363636363636],\n [873, 0.8295454545454546],\n [874, 0.7954545454545454],\n [875, 0.7954545454545454],\n [876, 0.75],\n [877, 0.75],\n [878, 0.7386363636363636],\n [879, 0.75],\n [880, 0.7272727272727273],\n [881, 0.8068181818181818],\n [882, 0.8181818181818182],\n [883, 0.7840909090909091],\n [884, 0.7954545454545454],\n [885, 0.8181818181818182],\n [886, 0.7840909090909091],\n [887, 0.8181818181818182],\n [888, 0.75],\n [889, 0.8068181818181818],\n [890, 0.7272727272727273],\n [891, 0.7840909090909091],\n [892, 0.7386363636363636],\n [893, 0.75],\n [894, 0.7727272727272727],\n [895, 0.7159090909090909],\n [896, 0.7613636363636364],\n [897, 0.7954545454545454],\n [898, 0.8409090909090909],\n [899, 0.8409090909090909],\n [900, 0.8068181818181818],\n [901, 0.7727272727272727],\n [902, 0.8068181818181818],\n [903, 0.7954545454545454],\n [904, 0.7840909090909091],\n [905, 0.7727272727272727],\n [906, 0.7840909090909091],\n [907, 0.7159090909090909],\n [908, 0.7954545454545454],\n [909, 0.7386363636363636],\n [910, 0.7727272727272727],\n [911, 0.8181818181818182],\n [912, 0.7386363636363636],\n [913, 0.7272727272727273],\n [914, 0.7954545454545454],\n [915, 0.8295454545454546],\n [916, 0.7954545454545454],\n [917, 0.7840909090909091],\n [918, 0.7727272727272727],\n [919, 0.7272727272727273],\n [920, 0.7727272727272727],\n [921, 0.7613636363636364],\n [922, 0.7727272727272727],\n [923, 0.7840909090909091],\n [924, 0.7727272727272727],\n [925, 0.7613636363636364],\n [926, 0.7159090909090909],\n [927, 0.75],\n [928, 0.6818181818181818],\n [929, 0.7840909090909091],\n [930, 0.8068181818181818],\n [931, 0.7954545454545454],\n [932, 0.7272727272727273],\n [933, 0.75],\n [934, 0.7840909090909091],\n [935, 0.8068181818181818],\n [936, 0.8068181818181818],\n [937, 0.7954545454545454],\n [938, 0.6704545454545454],\n [939, 0.7386363636363636],\n [940, 0.75],\n [941, 0.7272727272727273],\n [942, 0.7727272727272727],\n [943, 0.7272727272727273],\n [944, 0.8181818181818182],\n [945, 0.8295454545454546],\n [946, 0.8522727272727273],\n [947, 0.7727272727272727],\n [948, 0.7045454545454546],\n [949, 0.75],\n [950, 0.8409090909090909],\n [951, 0.8181818181818182],\n [952, 0.7386363636363636],\n [953, 0.7386363636363636],\n [954, 0.875],\n [955, 0.7613636363636364],\n [956, 0.6931818181818182],\n [957, 0.7954545454545454],\n [958, 0.7727272727272727],\n [959, 0.8636363636363636],\n [960, 0.8068181818181818],\n [961, 0.7613636363636364],\n [962, 0.7840909090909091],\n [963, 0.7613636363636364],\n [964, 0.75],\n [965, 0.7613636363636364],\n [966, 0.7840909090909091],\n [967, 0.7613636363636364],\n [968, 0.75],\n [969, 0.75],\n [970, 0.8068181818181818],\n [971, 0.8295454545454546],\n [972, 0.7954545454545454],\n [973, 0.8181818181818182],\n [974, 0.7386363636363636],\n [975, 0.75],\n [976, 0.7386363636363636],\n [977, 0.75],\n [978, 0.7840909090909091],\n [979, 0.8409090909090909],\n [980, 0.8068181818181818],\n [981, 0.6704545454545454],\n [982, 0.8181818181818182],\n [983, 0.6931818181818182],\n [984, 0.7727272727272727],\n [985, 0.7613636363636364],\n [986, 0.7613636363636364],\n [987, 0.75],\n [988, 0.7613636363636364],\n [989, 0.7159090909090909],\n [990, 0.7954545454545454],\n [991, 0.7386363636363636],\n [992, 0.7272727272727273],\n [993, 0.7727272727272727],\n [994, 0.8068181818181818],\n [995, 0.7954545454545454],\n [996, 0.75],\n [997, 0.7727272727272727],\n [998, 0.7159090909090909],\n [999, 0.7954545454545454]]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T11:06:06.863761141Z",
     "start_time": "2023-11-10T11:06:06.807033903Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T11:06:23.085066995Z",
     "start_time": "2023-11-10T11:06:23.081057187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns=[\"Seed\", \"Score\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T11:06:43.254319486Z",
     "start_time": "2023-11-10T11:06:43.252121846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "   Seed     Score\n0     0  0.806818\n1     1  0.784091\n2     2  0.795455\n3     3  0.784091\n4     4  0.806818",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Seed</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.806818</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.784091</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.795455</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.784091</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.806818</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T11:06:49.996369664Z",
     "start_time": "2023-11-10T11:06:49.970017610Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df.to_csv(\"prueba.csv\", )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T11:07:09.587697047Z",
     "start_time": "2023-11-10T11:07:09.572732830Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3d48d68c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3d48d6bb50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Mejor: 0.139929 usando {'epochs': 64, 'hidden_neurons': [16], 'lambda_regu': 0.01, 'n_classes': 10}\n",
      "0.119727 (0.041844) con: {'epochs': 64, 'hidden_neurons': [8], 'lambda_regu': 0.01, 'n_classes': 10}\n",
      "0.129828 (0.050963) con: {'epochs': 64, 'hidden_neurons': [8], 'lambda_regu': 0.001, 'n_classes': 10}\n",
      "0.139929 (0.037454) con: {'epochs': 64, 'hidden_neurons': [16], 'lambda_regu': 0.01, 'n_classes': 10}\n",
      "0.099525 (0.050072) con: {'epochs': 64, 'hidden_neurons': [16], 'lambda_regu': 0.001, 'n_classes': 10}\n",
      "0.109626 (0.056119) con: {'epochs': 64, 'hidden_neurons': [32], 'lambda_regu': 0.01, 'n_classes': 10}\n",
      "0.119430 (0.063840) con: {'epochs': 64, 'hidden_neurons': [32], 'lambda_regu': 0.001, 'n_classes': 10}\n",
      "0.119727 (0.041844) con: {'epochs': 128, 'hidden_neurons': [8], 'lambda_regu': 0.01, 'n_classes': 10}\n",
      "0.119727 (0.041844) con: {'epochs': 128, 'hidden_neurons': [8], 'lambda_regu': 0.001, 'n_classes': 10}\n",
      "0.119727 (0.041844) con: {'epochs': 128, 'hidden_neurons': [16], 'lambda_regu': 0.01, 'n_classes': 10}\n",
      "0.139929 (0.037454) con: {'epochs': 128, 'hidden_neurons': [16], 'lambda_regu': 0.001, 'n_classes': 10}\n",
      "0.129531 (0.070198) con: {'epochs': 128, 'hidden_neurons': [32], 'lambda_regu': 0.01, 'n_classes': 10}\n",
      "0.109626 (0.056119) con: {'epochs': 128, 'hidden_neurons': [32], 'lambda_regu': 0.001, 'n_classes': 10}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Establecer una semilla aleatoria para reproducibilidad\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class KerasGridSearchWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, hidden_neurons=[32], lambda_regu=0.01, n_classes=10, learning_rate=0.01, epochs=64, batch_size=128):\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.lambda_regu = lambda_regu\n",
    "        self.n_classes = n_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self._create_model()\n",
    "\n",
    "    def _create_model(self):\n",
    "        model = Sequential()\n",
    "        for neurons in self.hidden_neurons:\n",
    "            model.add(Dense(units=neurons, activation=\"relu\", kernel_regularizer=L2(self.lambda_regu)))\n",
    "        model.add(Dense(units=self.n_classes, activation=\"linear\", kernel_regularizer=L2(self.lambda_regu)))\n",
    "        model.compile(loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      optimizer=Adam(learning_rate=self.learning_rate),\n",
    "                      metrics='accuracy')\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, batch_size=self.batch_size,\n",
    "                        epochs=self.epochs, verbose=0)\n",
    "        return self\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.model.evaluate(X, y, verbose=0)[1]\n",
    "\n",
    "# Definir los hiperparámetros a ajustar\n",
    "param_grid = {\n",
    "    'hidden_neurons': [[8], [16], [32]],\n",
    "    'lambda_regu': [0.01, 0.001],\n",
    "    'n_classes': [10],\n",
    "    \"epochs\" : [64, 128]\n",
    "}\n",
    "\n",
    "# Crear el objeto GridSearchCV\n",
    "model = KerasGridSearchWrapper()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Datos de entrada y salida\n",
    "X = np.random.rand(100, 8)  # 100 muestras, 8 características cada una\n",
    "y = np.random.randint(0, 10, size=(100,))  # 100 etiquetas para un problema de 10 clases\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Mejor: %f usando %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) con: %r\" % (mean, stdev, param))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:24:30.509597004Z",
     "start_time": "2023-11-17T16:24:10.492924375Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hipers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T09:06:13.562556040Z",
     "start_time": "2023-11-19T09:06:13.556838142Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(\"data/hipers.json\") as f:\n",
    "    hipers = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T09:06:13.578711199Z",
     "start_time": "2023-11-19T09:06:13.559933141Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'sklearnMLP': {'hidden_layer_sizes': [[50], [100], [50, 50]],\n  'activation': ['logistic', 'tanh', 'relu'],\n  'solver': ['adam'],\n  'alpha': [0.0001, 0.001, 0.01],\n  'learning_rate': ['constant'],\n  'max_iter': [300, 400]},\n 'KerasMLP': {'epochs': [500, 750, 1000],\n  'batch_size': [64, 128],\n  'learning_rate': [0.001],\n  'lambda_regu': [0.01, 0.1],\n  'hidden_neurons': [[50], [100], [50, 50]]},\n 'RandomForestClassifier': {'n_estimators': [50, 70, 90],\n  'max_features': ['auto', 'sqrt', 'log2'],\n  'max_depth': [4, 8, 12],\n  'min_samples_split': [2, 5],\n  'min_samples_leaf': [1, 2, 3],\n  'bootstrap': [True, False]},\n 'AdaBoostClassifier': {'n_estimators': [50, 70, 90],\n  'learning_rate': [0.01, 0.1],\n  'algorithm': ['SAMME', 'SAMME.R']},\n 'BaggingClassifier': {'n_estimators': [10, 50, 100],\n  'max_samples': [0.5, 1.0],\n  'max_features': [0.5, 1.0],\n  'base_estimator__max_depth': [3, 5, 10]},\n 'DecisionTreeClassifier': {'max_depth': [None, 4, 8, 10],\n  'min_samples_split': [2, 8, 16, 32],\n  'min_samples_leaf': [2, 8, 16, 32, 48],\n  'max_features': [None, 'sqrt', 'log2'],\n  'criterion': ['gini', 'entropy', 'log_loss']},\n 'GaussianNB': {},\n 'KNeighborsClassifier': {'n_neighbors': [10, 25, 50, 65, 80],\n  'metric': ['minkowski'],\n  'p': [2]},\n 'LDA': {'solver': ['svd', 'lsqr', 'eigen'],\n  'priors': [None, [0.1, 0.9], [0.5, 0.5], [0.9, 0.1]],\n  'tol': [0.0001, 1e-05, 1e-06]},\n 'LogisticRegression': {'C': [0.001, 0.01, 0.1, 1],\n  'penalty': ['l1', 'l2'],\n  'max_iter': [1000, 2000, 3000, 4000, 5000]},\n 'QDA': {'priors': [None, [0.1, 0.9], [0.5, 0.5], [0.9, 0.1]],\n  'reg_param': [0.0, 0.1, 0.5],\n  'store_covariance': [False, True],\n  'tol': [0.0001, 1e-05]},\n 'RIPPER': {'prune-size': [0.1, 0.3, 0.5],\n  'k': [2, 3, 4],\n  'alpha': [0.1, 1.0, 2.0],\n  'n-discretize-bins': [10, 15, 20]},\n 'SVM': {'C': [0.1, 1],\n  'kernel': ['linear', 'rbf', 'sigmoid'],\n  'gamma': ['scale', 'auto']},\n 'StackingClassifier': {'svm__C': [0.1, 1],\n  'dt__max_depth': [3, 5, 7],\n  'final_estimator__C': [0.1, 1]},\n 'VotingClassifier': {'lr__C': [0.1, 1],\n  'svc__C': [0.1, 1],\n  'rf__n_estimators': [10, 50, 100],\n  'voting': ['soft', 'hard']}}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hipers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T09:06:13.612986494Z",
     "start_time": "2023-11-19T09:06:13.609303779Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[!h]\n",
      "    \\centering\n",
      "    \\caption{Hyperparameter Grid}\n",
      "    \\resizebox{\\textwidth}{!}{    \\begin{tabular}{|l|p{4cm}|p{4cm}|}\n",
      "        \\hline\n",
      "        \\textbf{Model} & \\textbf{Hyperparameter} & \\textbf{Values} \\\\\n",
      "        \\hline\n",
      "   sklearnMLP & \\textit{hidden layer sizes} & [50], [100], [50, 50] \\\\  \n",
      "    & \\textit{activation} & logistic, tanh, relu \\\\  \n",
      "    & \\textit{solver} & adam \\\\  \n",
      "    & \\textit{alpha} & 0.0001, 0.001, 0.01 \\\\  \n",
      "    & \\textit{learning rate} & constant \\\\  \n",
      "    & \\textit{max iter} & 300, 400 \\\\  \n",
      "        \\hline\n",
      "   KerasMLP & \\textit{epochs} & 500, 750, 1000 \\\\  \n",
      "    & \\textit{batch size} & 64, 128 \\\\  \n",
      "    & \\textit{learning rate} & 0.001 \\\\  \n",
      "    & \\textit{lambda regu} & 0.01, 0.1 \\\\  \n",
      "    & \\textit{hidden neurons} & [50], [100], [50, 50] \\\\  \n",
      "        \\hline\n",
      "   RandomForestClassifier & \\textit{n estimators} & 50, 70, 90 \\\\  \n",
      "    & \\textit{max features} & auto, sqrt, log2 \\\\  \n",
      "    & \\textit{max depth} & 4, 8, 12 \\\\  \n",
      "    & \\textit{min samples split} & 2, 5 \\\\  \n",
      "    & \\textit{min samples leaf} & 1, 2, 3 \\\\  \n",
      "    & \\textit{bootstrap} & True, False \\\\  \n",
      "        \\hline\n",
      "   AdaBoostClassifier & \\textit{n estimators} & 50, 70, 90 \\\\  \n",
      "    & \\textit{learning rate} & 0.01, 0.1 \\\\  \n",
      "    & \\textit{algorithm} & SAMME, SAMME.R \\\\  \n",
      "        \\hline\n",
      "   BaggingClassifier & \\textit{n estimators} & 10, 50, 100 \\\\  \n",
      "    & \\textit{max samples} & 0.5, 1.0 \\\\  \n",
      "    & \\textit{max features} & 0.5, 1.0 \\\\  \n",
      "    & \\textit{base estimator  max depth} & 3, 5, 10 \\\\  \n",
      "        \\hline\n",
      "   DecisionTreeClassifier & \\textit{max depth} & None, 4, 8, 10 \\\\  \n",
      "    & \\textit{min samples split} & 2, 8, 16, 32 \\\\  \n",
      "    & \\textit{min samples leaf} & 2, 8, 16, 32, 48 \\\\  \n",
      "    & \\textit{max features} & None, sqrt, log2 \\\\  \n",
      "    & \\textit{criterion} & gini, entropy, log_loss \\\\  \n",
      "        \\hline\n",
      "   KNeighborsClassifier & \\textit{n neighbors} & 10, 25, 50, 65, 80 \\\\  \n",
      "    & \\textit{metric} & minkowski \\\\  \n",
      "    & \\textit{p} & 2 \\\\  \n",
      "        \\hline\n",
      "   LDA & \\textit{solver} & svd, lsqr, eigen \\\\  \n",
      "    & \\textit{priors} & None, [0.1, 0.9], [0.5, 0.5], [0.9, 0.1] \\\\  \n",
      "    & \\textit{tol} & 0.0001, 1e-05, 1e-06 \\\\  \n",
      "        \\hline\n",
      "   LogisticRegression & \\textit{C} & 0.001, 0.01, 0.1, 1 \\\\  \n",
      "    & \\textit{penalty} & l1, l2 \\\\  \n",
      "    & \\textit{max iter} & 1000, 2000, 3000, 4000, 5000 \\\\  \n",
      "        \\hline\n",
      "   QDA & \\textit{priors} & None, [0.1, 0.9], [0.5, 0.5], [0.9, 0.1] \\\\  \n",
      "    & \\textit{reg param} & 0.0, 0.1, 0.5 \\\\  \n",
      "    & \\textit{store covariance} & False, True \\\\  \n",
      "    & \\textit{tol} & 0.0001, 1e-05 \\\\  \n",
      "        \\hline\n",
      "   RIPPER & \\textit{prune size} & 0.1, 0.3, 0.5 \\\\  \n",
      "    & \\textit{k} & 2, 3, 4 \\\\  \n",
      "    & \\textit{alpha} & 0.1, 1.0, 2.0 \\\\  \n",
      "    & \\textit{n discretize bins} & 10, 15, 20 \\\\  \n",
      "        \\hline\n",
      "   SVM & \\textit{C} & 0.1, 1 \\\\  \n",
      "    & \\textit{kernel} & linear, rbf, sigmoid \\\\  \n",
      "    & \\textit{gamma} & scale, auto \\\\  \n",
      "        \\hline\n",
      "   StackingClassifier & \\textit{svm  C} & 0.1, 1 \\\\  \n",
      "    & \\textit{dt  max depth} & 3, 5, 7 \\\\  \n",
      "    & \\textit{final estimator  C} & 0.1, 1 \\\\  \n",
      "        \\hline\n",
      "   VotingClassifier & \\textit{lr  C} & 0.1, 1 \\\\  \n",
      "    & \\textit{svc  C} & 0.1, 1 \\\\  \n",
      "    & \\textit{rf  n estimators} & 10, 50, 100 \\\\  \n",
      "    & \\textit{voting} & soft, hard \\\\  \n",
      "        \\hline\n",
      "    \\end{tabular}}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "latex_code = \"\\\\begin{table}[!h]\\n\"\n",
    "latex_code += \"    \\\\centering\\n\"\n",
    "latex_code += \"    \\\\caption{Hyperparameter Grid}\\n\"\n",
    "latex_code += \"    \\\\resizebox{\\\\textwidth}{!}{\"\n",
    "latex_code += \"    \\\\begin{tabular}{|l|p{4cm}|p{4cm}|}\\n\"\n",
    "latex_code += \"        \\\\hline\\n\"\n",
    "latex_code += \"        \\\\textbf{Model} & \\\\textbf{Hyperparameter} & \\\\textbf{Values} \\\\\\\\\\n\"\n",
    "\n",
    "previous_model = \"\"\n",
    "for model, params in hipers.items():\n",
    "    for param, values in params.items():\n",
    "        # Solo añadir el nombre del modelo si es diferente al anterior\n",
    "\n",
    "        if model != previous_model:\n",
    "            model_name = model\n",
    "            latex_code += \"        \\\\hline\\n\"\n",
    "        else:\n",
    "            model_name = \"\"\n",
    "\n",
    "        previous_model = model\n",
    "        param = \"\\\\textit{\" + param.replace(\"-\", \" \").replace(\"_\", \" \") + \"}\"\n",
    "        latex_code += f\"   {model_name} & {param} & {', '.join(map(str, values))} \\\\\\\\  \\n\"  # Eliminar valor de ejemplo\n",
    "\n",
    "latex_code += \"        \\\\hline\\n\"\n",
    "latex_code += \"    \\\\end{tabular}}\\n\"\n",
    "latex_code += \"\\\\end{table}\"\n",
    "\n",
    "print(latex_code)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T09:07:44.529808317Z",
     "start_time": "2023-11-19T09:07:44.488624914Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Brier Score\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example predictions and actual outcomes\n",
    "predictions = np.array([[0.7, 0.3], [0.2, 0.8], [0.9, 0.1]])  # Probabilities for each class\n",
    "actuals = np.array([[1, 0], [0, 1], [1, 0]])  # Actual class labels in one-hot encoding\n",
    "\n",
    "# Calculating the Brier score\n",
    "brier_scores = np.mean(np.sum((predictions - actuals)**2, axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:46:00.614834069Z",
     "start_time": "2023-11-18T19:46:00.457531390Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0.09333333333333334"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:46:04.739519538Z",
     "start_time": "2023-11-18T19:46:04.727563578Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "X_train, X_test, y_train, y_test = split(X,y , 8)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "score = model.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:48:00.679381791Z",
     "start_time": "2023-11-18T19:48:00.673052933Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "probas = model.predict_proba(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:49:12.102868729Z",
     "start_time": "2023-11-18T19:49:12.100418897Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[9.99992819e-001, 7.18074409e-006],\n       [1.40741234e-007, 9.99999859e-001],\n       [9.99994137e-001, 5.86268764e-006],\n       [4.37411642e-025, 1.00000000e+000],\n       [9.99999838e-001, 1.62253494e-007],\n       [1.43832941e-006, 9.99998562e-001],\n       [1.13944979e-009, 9.99999999e-001],\n       [4.37861634e-009, 9.99999996e-001],\n       [9.76565910e-005, 9.99902343e-001],\n       [1.10254389e-017, 1.00000000e+000],\n       [6.88722637e-004, 9.99311277e-001],\n       [9.99999920e-001, 8.03194225e-008],\n       [1.94331699e-026, 1.00000000e+000],\n       [1.98214266e-008, 9.99999980e-001],\n       [1.74945314e-083, 1.00000000e+000],\n       [6.82381575e-099, 1.00000000e+000],\n       [9.99948083e-001, 5.19170646e-005],\n       [9.99999960e-001, 4.04228568e-008],\n       [9.99999733e-001, 2.66782008e-007],\n       [1.93519133e-002, 9.80648087e-001],\n       [5.87512879e-003, 9.94124871e-001],\n       [9.99994856e-001, 5.14382623e-006],\n       [9.98376348e-001, 1.62365248e-003],\n       [1.27476003e-129, 1.00000000e+000],\n       [9.99994060e-001, 5.93964005e-006],\n       [9.99039268e-001, 9.60732170e-004],\n       [1.32334866e-124, 1.00000000e+000],\n       [9.99999293e-001, 7.06735316e-007],\n       [3.12793781e-001, 6.87206219e-001],\n       [9.99919734e-001, 8.02662290e-005],\n       [9.99999891e-001, 1.09128532e-007],\n       [9.99976862e-001, 2.31376913e-005],\n       [9.96601331e-001, 3.39866944e-003],\n       [5.13783090e-154, 1.00000000e+000],\n       [9.99999998e-001, 2.34271106e-009],\n       [9.99997954e-001, 2.04645240e-006],\n       [9.99367358e-001, 6.32642253e-004],\n       [9.99995819e-001, 4.18096670e-006],\n       [9.98083929e-001, 1.91607097e-003],\n       [2.59159377e-087, 1.00000000e+000],\n       [9.99271019e-001, 7.28981338e-004],\n       [9.99999761e-001, 2.39276924e-007],\n       [4.89466116e-001, 5.10533884e-001],\n       [1.14925584e-078, 1.00000000e+000],\n       [4.93600989e-130, 1.00000000e+000],\n       [8.07385039e-130, 1.00000000e+000],\n       [3.25271107e-004, 9.99674729e-001],\n       [9.99999726e-001, 2.74197458e-007],\n       [5.17238800e-133, 1.00000000e+000],\n       [4.03703458e-088, 1.00000000e+000],\n       [9.99999960e-001, 4.00710125e-008],\n       [9.99994649e-001, 5.35122864e-006],\n       [9.99999805e-001, 1.94709076e-007],\n       [9.55231410e-001, 4.47685901e-002],\n       [3.79242966e-051, 1.00000000e+000],\n       [9.99493153e-001, 5.06847460e-004],\n       [9.23240487e-001, 7.67595135e-002],\n       [9.99999769e-001, 2.31488823e-007],\n       [9.99997616e-001, 2.38446987e-006],\n       [2.72341493e-007, 9.99999728e-001],\n       [9.99999797e-001, 2.02546934e-007],\n       [2.60605456e-001, 7.39394544e-001],\n       [9.99999982e-001, 1.82813372e-008],\n       [9.99988427e-001, 1.15726755e-005],\n       [2.29491608e-001, 7.70508392e-001],\n       [9.99982349e-001, 1.76514787e-005],\n       [7.96069515e-130, 1.00000000e+000],\n       [9.99991403e-001, 8.59695295e-006],\n       [9.99866546e-001, 1.33453564e-004],\n       [9.99983386e-001, 1.66137252e-005],\n       [9.99673911e-001, 3.26088832e-004],\n       [5.45500113e-156, 1.00000000e+000],\n       [9.99993272e-001, 6.72845724e-006],\n       [9.99738893e-001, 2.61107099e-004],\n       [9.99983632e-001, 1.63684115e-005],\n       [9.99993718e-001, 6.28212115e-006],\n       [4.44519684e-020, 1.00000000e+000],\n       [5.06208247e-015, 1.00000000e+000],\n       [9.99999988e-001, 1.18037742e-008],\n       [9.99998292e-001, 1.70834678e-006],\n       [9.99974731e-001, 2.52694782e-005],\n       [9.99999969e-001, 3.13461121e-008],\n       [9.97743899e-001, 2.25610057e-003],\n       [6.91399340e-042, 1.00000000e+000],\n       [9.33492335e-025, 1.00000000e+000],\n       [9.99999950e-001, 5.02348951e-008],\n       [9.99971543e-001, 2.84565300e-005],\n       [9.99999973e-001, 2.72275725e-008]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:49:17.710302396Z",
     "start_time": "2023-11-18T19:49:17.705808065Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([7.18074409e-06, 9.99999859e-01, 5.86268764e-06, 1.00000000e+00,\n       1.62253494e-07, 9.99998562e-01, 9.99999999e-01, 9.99999996e-01,\n       9.99902343e-01, 1.00000000e+00, 9.99311277e-01, 8.03194225e-08,\n       1.00000000e+00, 9.99999980e-01, 1.00000000e+00, 1.00000000e+00,\n       5.19170646e-05, 4.04228568e-08, 2.66782008e-07, 9.80648087e-01,\n       9.94124871e-01, 5.14382623e-06, 1.62365248e-03, 1.00000000e+00,\n       5.93964005e-06, 9.60732170e-04, 1.00000000e+00, 7.06735316e-07,\n       6.87206219e-01, 8.02662290e-05, 1.09128532e-07, 2.31376913e-05,\n       3.39866944e-03, 1.00000000e+00, 2.34271106e-09, 2.04645240e-06,\n       6.32642253e-04, 4.18096670e-06, 1.91607097e-03, 1.00000000e+00,\n       7.28981338e-04, 2.39276924e-07, 5.10533884e-01, 1.00000000e+00,\n       1.00000000e+00, 1.00000000e+00, 9.99674729e-01, 2.74197458e-07,\n       1.00000000e+00, 1.00000000e+00, 4.00710125e-08, 5.35122864e-06,\n       1.94709076e-07, 4.47685901e-02, 1.00000000e+00, 5.06847460e-04,\n       7.67595135e-02, 2.31488823e-07, 2.38446987e-06, 9.99999728e-01,\n       2.02546934e-07, 7.39394544e-01, 1.82813372e-08, 1.15726755e-05,\n       7.70508392e-01, 1.76514787e-05, 1.00000000e+00, 8.59695295e-06,\n       1.33453564e-04, 1.66137252e-05, 3.26088832e-04, 1.00000000e+00,\n       6.72845724e-06, 2.61107099e-04, 1.63684115e-05, 6.28212115e-06,\n       1.00000000e+00, 1.00000000e+00, 1.18037742e-08, 1.70834678e-06,\n       2.52694782e-05, 3.13461121e-08, 2.25610057e-03, 1.00000000e+00,\n       1.00000000e+00, 5.02348951e-08, 2.84565300e-05, 2.72275725e-08])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[:, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:49:20.064424830Z",
     "start_time": "2023-11-18T19:49:20.023328245Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:49:51.969196758Z",
     "start_time": "2023-11-18T19:49:51.931002474Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score: 0.13880496219137098\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Brier score\n",
    "brier_score = brier_score_loss(y_test, probas[:, 1])\n",
    "\n",
    "print(\"Brier score:\", brier_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T19:50:06.385720388Z",
     "start_time": "2023-11-18T19:50:06.381222665Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
